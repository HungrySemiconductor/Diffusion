# Course_Notes

## 1. 扩散模型结构学习

- **退化过程**：逐步添加噪声

- **UNet网络**

  - 作用：接收噪声图像，输出预测结果
  - 网络结构：对称的下采样（编码器，压缩数据维度）和上采样（解码器，扩展回原始维度）路径，并通过残差连接（跳跃连接，允许信息和梯度在不同层级之间流动）将编码器的特征与解码器的特征结合

- **简单的BasicNet训练模型**：输入一个带噪数据，输出对其最佳预测，通过均方误差对预测值与真实值进行比较

  - 获取一批数据
  - 添加随机噪声
  - 将数据输入模型
  - 对模型预测与初始图像进行比较，计算损失更新模型的参数

  <img src=".\imgs\Figure_1-1769348077706.png" alt="img" style="zoom: 33%;" />

- **采样理论**：从完全噪声开始，每次都检查一下预测结果，如果新的预测结果比上一次的好，就将其输入模型以获得新的预测结果

  <img src=".\imgs\Figure_2.png" alt="img" style="zoom: 80%;" />

- **复杂的UNet2DModel模型**：Diffusers库中的DDPM版本

  - **预测噪声而非去噪的图像**：不同的任务目标对模型性能有影响
  - DDPM让模型 **预测退化过程中使用的噪声**（单位正态分布的噪声，均值为0，方差为1）**epsilon**（当前流行的方法），之后再得到去噪的图像。这种方法使权重向预测更低的噪声量收敛
    - 也可以让模型 **预测 ”同时受图像和噪声影响的“ velocity组合**

- **采样步长设置（timestep）需要考虑的问题**：通过调节时间步来调节噪声量：向模型提供有关噪声量的信息，可以提升模型性能

  - 一步走多远？
  - 预测更多次，用更高阶的梯度来更新得到更准确的结果？
  - 保留历史预测值来指导当前步的更新？
  - 在采样过程中额外添加噪声（随机噪声或确定噪声）？

## 2. 训练自定义扩散模型













---

[1] 扩散模型从原理到实战, 李忻玮, 苏步升, 徐浩然, 余海铭, 人民邮电出版社

<img src=".\imgs\image-20260124184542838.png" alt="image-20260124184542838" style="zoom:33%;" />



---

# Diffusion介绍

> DDPM (Denoising Diffusion Probabilistic Model)去噪扩散概率模型
>
> **扩散模型预测的是噪声残差**，即要求反向过程中预测的噪声分布与前向过程中施加的噪声分布之间的“距离”最小
>
> 训练时只需要用MSE损失来最小化前向施加的噪声分布和反向预测的噪声分布，就能实现优化目标

## 1 生成模型

### 1.1 生成模型原理

> 在生成模型中，我们假设数据来自一个未知的真实分布。我们定义一个模型分布（比如神经网络），然后用最大似然来调整模型参数，让模型估计的分布接近真实分布，然后从中采样（生成）新数据

- 生成模型：生成模型的目标是学习训练数据中的规律，然后**创造出类似的新数据**，本质上是**对真实数据背后的概率分布进行建模和采样**

- 最大似然估计：最大似然是一种**学习准则**。它的思想是：一个好的模型，应该让你观测到的数据（训练集）出现的**概率最大**
- 模型对比：
  - **GAN**：是**一步到位**的“博弈”。生成器试图直接生成逼真假货，判别器努力鉴别真伪。两者在对抗中共同进化。
  - **扩散模型**：是**循序渐进**的“去噪”。它先定义了一个将数据逐步加噪声直至变成纯噪声的过程（前向过程），然后训练一个网络**学习如何一步步地把噪声还原成数据**（逆向过程）。

---

## 2 扩散模型

### 2.1 扩散模型原理

> 扩散过程分为前向过程和反向过程两个部分
>
> **前向过程**：给数据添加噪声，迭代和加噪次数够大根据马尔可夫链性质，就可以得到纯随机噪声分布的数据
>
> **反向过程**：去噪（从随机噪声中迭代恢复出清晰数据）

##### 1. 扩散过程定义
- **前向过程（Forward Process/Diffusion Process）**：
  - 逐步向原始数据 $x_0$ 添加高斯噪声
  - 在 $T$ 步后，数据完全退化为各向同性高斯噪声
  - 数学形式：$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)$
  - 其中 $\beta_t$ 是噪声调度参数（0 < $\beta_t$ < 1），控制每次添加的噪声量

- **反向过程（Reverse Process）**：
  - 从噪声 $x_T \sim \mathcal{N}(0, I)$ 开始
  - 逐步去除噪声，恢复原始数据分布
  - 数学形式：$p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$
  - 神经网络 $\theta$ 学习均值和方差参数

##### 2. 噪声分布假设
- **核心假设**：所有添加的噪声都是**高斯噪声**
- 前向过程的闭式解（通过重参数化技巧）：
  $
  x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
  $
  其中：
  - $\alpha_t = 1 - \beta_t$
  - $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$
  - 这意味着可以直接从 $x_0$ 计算任意时刻 $t$ 的 $x_t$

##### 3. 马尔可夫链性质
- **马尔可夫性**：下一状态仅依赖于当前状态，与历史状态无关
  - 前向过程：$q(x_{1:T} | x_0) = \prod_{t=1}^T q(x_t | x_{t-1})$
  - 反向过程：$p_\theta(x_{0:T}) = p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t)$
- **平稳分布**：经过足够多步（$T \to \infty$），分布收敛到标准高斯分布 $\mathcal{N}(0, I)$

##### 4. 随机微分方程视角（SDE）
- **连续时间形式**：
  - 前向SDE：$dx = f(x,t)dt + g(t)dw$
    - $f(x,t)$：漂移系数
    - $g(t)$：扩散系数
    - $w$：维纳过程（布朗运动）
  - 反向SDE：$dx = [f(x,t) - g(t)^2 \nabla_x \log p_t(x)]dt + g(t)d\bar{w}$
    - $\nabla_x \log p_t(x)$：分数函数（score function）
- **离散化**：DDPM是SDE的离散时间特例

##### 5. 损失函数表征
- **核心目标**：学习反向过程的参数 $\theta$
- **损失函数推导**（变分下界，ELBO）：
  $
  \mathbb{E}_{q(x_0)}[-\log p_\theta(x_0)] \leq \mathbb{E}_{q(x_{0:T})}\left[\log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}\right]
  $
  
- **简化损失**（DDPM的关键贡献）：
  $
  L_{\text{simple}} = \mathbb{E}_{t,x_0,\epsilon} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]
  $
  其中：
  - $t \sim \text{Uniform}({1,\dots,T})$
  - $x_0 \sim q(x_0)$：训练数据
  - $\epsilon \sim \mathcal{N}(0, I)$：前向过程中实际添加的噪声
  - $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon$
  - $\epsilon_\theta$：神经网络预测的噪声

- **损失函数的三种等价形式**：
  1. **噪声预测**：$L = \|\epsilon - \epsilon_\theta(x_t, t)\|^2$（最常用）
  2. **数据预测**：$L = \|x_0 - \hat{x}_0(x_t, t)\|^2$
  3. **分数匹配**：$L = \|s_\theta(x_t, t) - \nabla_{x_t} \log q(x_t)\|^2$
     其中 $s_\theta$ 是分数函数估计器

##### 6. 关键算法步骤
**训练过程**：
```
for 每个训练批次:
    1. 采样真实数据 x0 ~ q(x0)
    2. 采样时间步 t ~ Uniform({1,...,T})
    3. 采样噪声 ε ~ N(0, I)
    4. 计算加噪数据: xt = √ᾱt·x0 + √(1-ᾱt)·ε
    5. 网络预测: ε_θ = ϵ_θ(xt, t)
    6. 计算损失: L = MSE(ε, ε_θ)
    7. 反向传播更新网络参数
```

**采样过程**：
```
1. 采样初始噪声 xT ~ N(0, I)
2. for t = T to 1:
    3. 采样 z ~ N(0, I) if t > 1 else z = 0
    4. 预测噪声: ε_θ = ϵ_θ(xt, t)
    5. 计算均值: μ_θ = (1/√αt)·[xt - (1-αt)/√(1-ᾱt)·ε_θ]
    6. 更新: x_{t-1} = μ_θ + σt·z
    其中 σt^2 = βt 或根据方差调度确定
3. 返回 x0（生成的样本）
```

**优点**：
- ✅ 训练稳定（简单回归任务）
- ✅ 生成质量高、多样性好
- ✅ 理论优雅，有坚实的数学基础
- ✅ 灵活的 conditioning 机制

**缺点**：
- ❌ 采样速度慢（需要多次迭代）
- ❌ 计算成本高（训练和推理）
- ❌ 难以控制中间生成过程
- ❌ 对超参数（如噪声调度）敏感

### 2.2 扩散模型发展

##### 1. 基础扩散模型提出与改进

`DDPM` 去噪扩散概率模型应用到图像生成任务

##### 2. 加速生成：采样器

生成速度非常慢（图像生成阶段迭代多次），生成速度与质量取决于采样器

`Score-Based Generative Modeling through Stochastic Differential Equations` 表明DDPM采样过程是随机微分方程，通过更离散化地求解就可以所见采样步数，提高生成速度

优秀的求解器：Euler、SDE、DPM-Solver++、Karrars等

##### 3. 基于现实分类器引导的扩散模型

`Diffusion Models Beat GANs on Image Synthesis` 扩散工程中如何用显示分类器引导，打败图像生成领域统治多年的GAN，展示了扩散模型的强大潜力

##### 4. 基于CLIP的多模态图像生成

`CLIP` 将同一语义的文字和图片连接的模型，这项技术与扩散模型的结合，引起基于文字引导的文字生成图像扩散模型 `Imagen、Stable Diffusion`

##### 5. 基于现有扩散模型的再学习

`DreamBooth` 现有模型再学习指定主体图像，将指定主体图像绑定到唯一的文本标识后，可以使用提示词控制主体生成不同的场景下的图像

`ControlNet` 再学习到更多模态信息，利用分割图、边缘图精细控制图像生成

### 2.3 扩散模型应用

- 计算机视觉，目标分割检测，超分辨率，图像修复翻译编辑
- **时序数据预测，基于历史观测数据预测未来数据**
- 自然语言
- 基于文本多模态，文本生成图像、视频、3D
- AI基础科学

---

# Problems & Methods

- 找不到cuda、gpu

  > cuda与驱动程序版本不匹配？cuda与torch版本不匹配？
  >
  > ```
  > print(torch.__version__)		
  > print(torch.cuda.is_available())
  > device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  > print(f'Using device: {device}')
  > ```
  >
  > 如果版本不匹配需要卸载 `torch` 和 `torchvision` ，然后在 `Pytorch` 官网选择相应版本进行安装

